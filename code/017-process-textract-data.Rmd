---
title: "process textract data"
author: "JJayes"
date: "01/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```

```{r}
require(data.table)


#Get a list with all csv files from the directory that is set as 'working directory'
filelist = list.files(path = "./data/textract/",
                      pattern="*.csv$") %>% 
  as_tibble() %>% 
  rename(filename = value) %>% 
  mutate(path = str_c("data/textract/", filename))

df <- filelist %>% 
  mutate(data= map(path, ~ fread(., encoding = "UTF-8")))

df <- df %>% 
  unnest(data)

```

This gets me to one sentence per line

```{r}
df <- df %>% 
  mutate(Text = str_remove_all(Text, "\\[|\\]")) %>% 
  separate_rows(Text, sep = "'") %>% 
  mutate(Text = str_remove_all(Text, "[:punct:]"),
         Text = str_squish(Text)) %>% 
  filter(nchar(Text) > 1)

df <- df %>%
  select(-path) %>%
  mutate(filename = str_remove(filename, "\\.csv")) %>%
  rename(patent = filename) %>%
  janitor::clean_names()
```

```{r}
patents <- read_rds("data/patent-info-prv/Electricity_patents_list_prv_19-01-22.rds")

df <- df %>% mutate(publication_number = str_remove(patent, "SE")) %>% 
  inner_join(patents)

df <- df %>% 
  mutate(year = year(filing_date),
         decade = year - year %% 10) %>% 
  select(-year)
```


```{r}
library(tidylo)
library(tidytext)

library(stopwords)

stopwords_sv <- stopwords(language = "sv") %>% 
  as_tibble() %>% 
  rename(word = value)

df_tidylo <- df %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stopwords_sv)


df_tidylo_counts <- df_tidylo %>% 
  count(word, decade, sort = T)

df_tidylo_log_odds <- df_tidylo_counts %>%
  bind_log_odds(decade, word, n) 

df_tidylo_log_odds %>%
  arrange(-log_odds_weighted)

# df_tidylo_log_odds %>% write_rds("data/patent-info-prv/electric_patent_graphic.rds")

df_tidylo_log_odds %>%
  filter(nchar(word) > 4,
         !word %in% c("genom", "enligt")) %>% 
  group_by(decade) %>%
  top_n(10) %>%
  ungroup %>%
  mutate(word = reorder(word, log_odds_weighted)) %>%
  ggplot(aes(log_odds_weighted, word, fill = factor(decade))) +
  geom_col(show.legend = FALSE) +
  scale_fill_brewer(palette = "Dark2") +
  facet_wrap(~decade, scales = "free") +
  labs(y = NULL,
       x = "Specificity of word to decade's patents") 
```




at page 11 of results

Following: [this tutorial](https://www.youtube.com/watch?v=7z7U7ORFWQM)

```{r}
library(quanteda)

corp = corpus(df, docnames = "filename", text_field = "Text")

dtm = dfm(corp, stem = T, remove = stopwords("sv"), remove_punct = T)

dtm <- dfm_trim(dtm, min_termfreq = 10)
dtm
```

```{r}
library(tidytext)

df %>% 
  unnest_tokens(word, Text) %>%
  anti_join(stopwords("sv") %>% as_tibble() %>% rename(word = value)) %>% 
  filter(nchar(word) > 3,
         str_detect(word, "[a-z]")) %>% 
  count(word, sort =T) %>% view
```




Working with quanteda

```{r}
library(readtext)

df <- readtext(file = "data/textract/patents_combined.csv", 
               text_field = "text",
               docid_field = "patent")

df <- corpus(df, docnames = "patent")
```

